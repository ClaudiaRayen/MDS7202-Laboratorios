{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3lcjo7KqEbX"
      },
      "source": [
        "![](https://www.dii.uchile.cl/wp-content/uploads/2021/06/Magi%CC%81ster-en-Ciencia-de-Datos.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fv4drk-lqEbc"
      },
      "source": [
        "# **Proyecto 1 - MDS7202 Laboratorio de Programación Científica para Ciencia de Datos 📚**\n",
        "\n",
        "**MDS7202: Laboratorio de Programación Científica para Ciencia de Datos**\n",
        "\n",
        "### Cuerpo Docente:\n",
        "\n",
        "- Profesor: Ignacio Meza, Gabriel Iturra\n",
        "- Auxiliar: Sebastián Tinoco\n",
        "- Ayudante: Arturo Lazcano, Angelo Muñoz\n",
        "\n",
        "*Por favor, lean detalladamente las instrucciones de la tarea antes de empezar a escribir.*\n",
        "\n",
        "### Equipo:\n",
        "\n",
        "- Michelle Avendaño\n",
        "- Claudia Navarro\n",
        "\n",
        "\n",
        "### Link de repositorio de GitHub: `\\<http://....\\>`\n",
        "\n",
        "Fecha límite de entrega 📆: 06 de Noviembre de 2023."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30CZu0GOqEbd"
      },
      "source": [
        "----\n",
        "\n",
        "## Reglas\n",
        "\n",
        "- **Grupos de 2 personas.**\n",
        "- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente serán respondidos por este medio.\n",
        "- Estrictamente prohibida la copia.\n",
        "- Pueden usar cualquier material del curso que estimen conveniente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bimklLspqEbe"
      },
      "source": [
        "<div style=\"text-align: center;\">\n",
        "    <img src=\"https://worldskateamerica.org/wp-content/uploads/2023/07/SANTIAGO-2023-1-768x153.jpg\" alt=\"Descripción de la imagen\">\n",
        "</div>\n",
        "\n",
        "En un Chile azotado por un profundo caos político-económico y el resurgimiento de programas de televisión de dudosa calidad, todas las miradas y esperanzas son depositadas en el éxito de un único evento: Santiago 2023. La nación necesitaba desesperadamente un respiro, y los Juegos de Santiago 2023 prometían ser una luz al final del túnel.\n",
        "\n",
        "El Presidente de la República -conocido en las calles como Bombín-, consciente de la importancia de este evento para la revitalización del país, decide convocar a usted y su equipo en calidad de expertos en análisis de datos y estadísticas. Con gran solemnidad, el presidente les encomienda una importante y peligrosa: liderar un proyecto que permitiera caracterizar de forma automática y eficiente los datos generados por estos magnos juegos. Para esto, el presidente le destaca que la solución debe considerar los siguientes puntos:\n",
        "- Caracterización automática de los datos\n",
        "- La solución debe ser compatible con cualquier dataset\n",
        "- Se les facilita el dataset *olimpiadas.parquet*, el cual recopila data de diferentes juegos olímpicos realizados en los últimos años"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#importamos librería\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import datetime\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import FunctionTransformer, MinMaxScaler, OneHotEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.covariance import EllipticEnvelope\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats import chi2_contingency\n",
        "import re"
      ],
      "metadata": {
        "id": "3ziBjq8Eq0Bn"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_parquet('/content/olimpiadas.parquet')\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "E-VPdBZNq6rV",
        "outputId": "66d4721c-832a-404e-dace-3d1b87bc0d27"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            ID                      Name Sex            Team  NOC  \\\n",
              "0            1                 A Dijiang   M           China  CHN   \n",
              "1            2                  A Lamusi   M           China  CHN   \n",
              "2            3       Gunnar Nielsen Aaby   M         Denmark  DEN   \n",
              "3            4      Edgar Lindenau Aabye   M  Denmark/Sweden  DEN   \n",
              "4            5  Christine Jacoba Aaftink   F     Netherlands  NED   \n",
              "...        ...                       ...  ..             ...  ...   \n",
              "271111  135569                Andrzej ya   M        Poland-1  POL   \n",
              "271112  135570                  Piotr ya   M          Poland  POL   \n",
              "271113  135570                  Piotr ya   M          Poland  POL   \n",
              "271114  135571        Tomasz Ireneusz ya   M          Poland  POL   \n",
              "271115  135571        Tomasz Ireneusz ya   M          Poland  POL   \n",
              "\n",
              "              Games  Year  Season            City          Sport  \\\n",
              "0       1992 Summer  1992  Summer       Barcelona     Basketball   \n",
              "1       2012 Summer  2012  Summer          London           Judo   \n",
              "2       1920 Summer  1920  Summer       Antwerpen       Football   \n",
              "3       1900 Summer  1900  Summer           Paris     Tug-Of-War   \n",
              "4       1988 Winter  1988  Winter         Calgary  Speed Skating   \n",
              "...             ...   ...     ...             ...            ...   \n",
              "271111  1976 Winter  1976  Winter       Innsbruck           Luge   \n",
              "271112  2014 Winter  2014  Winter           Sochi    Ski Jumping   \n",
              "271113  2014 Winter  2014  Winter           Sochi    Ski Jumping   \n",
              "271114  1998 Winter  1998  Winter          Nagano      Bobsleigh   \n",
              "271115  2002 Winter  2002  Winter  Salt Lake City      Bobsleigh   \n",
              "\n",
              "                                           Event Medal age-height-weight  \n",
              "0                    Basketball Men's Basketball  None   24.0*180.0?80.0  \n",
              "1                   Judo Men's Extra-Lightweight  None   23.0(170.0?60.0  \n",
              "2                        Football Men's Football  None      24.0(nan?nan  \n",
              "3                    Tug-Of-War Men's Tug-Of-War  Gold      34.0:nan?nan  \n",
              "4               Speed Skating Women's 500 metres  None   21.0(185.0?82.0  \n",
              "...                                          ...   ...               ...  \n",
              "271111                Luge Mixed (Men)'s Doubles  None   29.0:179.0?89.0  \n",
              "271112  Ski Jumping Men's Large Hill, Individual  None   27.0:176.0?59.0  \n",
              "271113        Ski Jumping Men's Large Hill, Team  None   27.0*176.0?59.0  \n",
              "271114                      Bobsleigh Men's Four  None   30.0(185.0?96.0  \n",
              "271115                      Bobsleigh Men's Four  None   34.0(185.0?96.0  \n",
              "\n",
              "[271116 rows x 13 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dc2e5981-45ec-42ef-827a-3734bebcd85c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Team</th>\n",
              "      <th>NOC</th>\n",
              "      <th>Games</th>\n",
              "      <th>Year</th>\n",
              "      <th>Season</th>\n",
              "      <th>City</th>\n",
              "      <th>Sport</th>\n",
              "      <th>Event</th>\n",
              "      <th>Medal</th>\n",
              "      <th>age-height-weight</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>A Dijiang</td>\n",
              "      <td>M</td>\n",
              "      <td>China</td>\n",
              "      <td>CHN</td>\n",
              "      <td>1992 Summer</td>\n",
              "      <td>1992</td>\n",
              "      <td>Summer</td>\n",
              "      <td>Barcelona</td>\n",
              "      <td>Basketball</td>\n",
              "      <td>Basketball Men's Basketball</td>\n",
              "      <td>None</td>\n",
              "      <td>24.0*180.0?80.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>A Lamusi</td>\n",
              "      <td>M</td>\n",
              "      <td>China</td>\n",
              "      <td>CHN</td>\n",
              "      <td>2012 Summer</td>\n",
              "      <td>2012</td>\n",
              "      <td>Summer</td>\n",
              "      <td>London</td>\n",
              "      <td>Judo</td>\n",
              "      <td>Judo Men's Extra-Lightweight</td>\n",
              "      <td>None</td>\n",
              "      <td>23.0(170.0?60.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Gunnar Nielsen Aaby</td>\n",
              "      <td>M</td>\n",
              "      <td>Denmark</td>\n",
              "      <td>DEN</td>\n",
              "      <td>1920 Summer</td>\n",
              "      <td>1920</td>\n",
              "      <td>Summer</td>\n",
              "      <td>Antwerpen</td>\n",
              "      <td>Football</td>\n",
              "      <td>Football Men's Football</td>\n",
              "      <td>None</td>\n",
              "      <td>24.0(nan?nan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Edgar Lindenau Aabye</td>\n",
              "      <td>M</td>\n",
              "      <td>Denmark/Sweden</td>\n",
              "      <td>DEN</td>\n",
              "      <td>1900 Summer</td>\n",
              "      <td>1900</td>\n",
              "      <td>Summer</td>\n",
              "      <td>Paris</td>\n",
              "      <td>Tug-Of-War</td>\n",
              "      <td>Tug-Of-War Men's Tug-Of-War</td>\n",
              "      <td>Gold</td>\n",
              "      <td>34.0:nan?nan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Christine Jacoba Aaftink</td>\n",
              "      <td>F</td>\n",
              "      <td>Netherlands</td>\n",
              "      <td>NED</td>\n",
              "      <td>1988 Winter</td>\n",
              "      <td>1988</td>\n",
              "      <td>Winter</td>\n",
              "      <td>Calgary</td>\n",
              "      <td>Speed Skating</td>\n",
              "      <td>Speed Skating Women's 500 metres</td>\n",
              "      <td>None</td>\n",
              "      <td>21.0(185.0?82.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>271111</th>\n",
              "      <td>135569</td>\n",
              "      <td>Andrzej ya</td>\n",
              "      <td>M</td>\n",
              "      <td>Poland-1</td>\n",
              "      <td>POL</td>\n",
              "      <td>1976 Winter</td>\n",
              "      <td>1976</td>\n",
              "      <td>Winter</td>\n",
              "      <td>Innsbruck</td>\n",
              "      <td>Luge</td>\n",
              "      <td>Luge Mixed (Men)'s Doubles</td>\n",
              "      <td>None</td>\n",
              "      <td>29.0:179.0?89.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>271112</th>\n",
              "      <td>135570</td>\n",
              "      <td>Piotr ya</td>\n",
              "      <td>M</td>\n",
              "      <td>Poland</td>\n",
              "      <td>POL</td>\n",
              "      <td>2014 Winter</td>\n",
              "      <td>2014</td>\n",
              "      <td>Winter</td>\n",
              "      <td>Sochi</td>\n",
              "      <td>Ski Jumping</td>\n",
              "      <td>Ski Jumping Men's Large Hill, Individual</td>\n",
              "      <td>None</td>\n",
              "      <td>27.0:176.0?59.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>271113</th>\n",
              "      <td>135570</td>\n",
              "      <td>Piotr ya</td>\n",
              "      <td>M</td>\n",
              "      <td>Poland</td>\n",
              "      <td>POL</td>\n",
              "      <td>2014 Winter</td>\n",
              "      <td>2014</td>\n",
              "      <td>Winter</td>\n",
              "      <td>Sochi</td>\n",
              "      <td>Ski Jumping</td>\n",
              "      <td>Ski Jumping Men's Large Hill, Team</td>\n",
              "      <td>None</td>\n",
              "      <td>27.0*176.0?59.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>271114</th>\n",
              "      <td>135571</td>\n",
              "      <td>Tomasz Ireneusz ya</td>\n",
              "      <td>M</td>\n",
              "      <td>Poland</td>\n",
              "      <td>POL</td>\n",
              "      <td>1998 Winter</td>\n",
              "      <td>1998</td>\n",
              "      <td>Winter</td>\n",
              "      <td>Nagano</td>\n",
              "      <td>Bobsleigh</td>\n",
              "      <td>Bobsleigh Men's Four</td>\n",
              "      <td>None</td>\n",
              "      <td>30.0(185.0?96.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>271115</th>\n",
              "      <td>135571</td>\n",
              "      <td>Tomasz Ireneusz ya</td>\n",
              "      <td>M</td>\n",
              "      <td>Poland</td>\n",
              "      <td>POL</td>\n",
              "      <td>2002 Winter</td>\n",
              "      <td>2002</td>\n",
              "      <td>Winter</td>\n",
              "      <td>Salt Lake City</td>\n",
              "      <td>Bobsleigh</td>\n",
              "      <td>Bobsleigh Men's Four</td>\n",
              "      <td>None</td>\n",
              "      <td>34.0(185.0?96.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>271116 rows × 13 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dc2e5981-45ec-42ef-827a-3734bebcd85c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-dc2e5981-45ec-42ef-827a-3734bebcd85c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-dc2e5981-45ec-42ef-827a-3734bebcd85c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-83dc446c-ae26-4ef2-91a0-01ffd6b97bcd\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-83dc446c-ae26-4ef2-91a0-01ffd6b97bcd')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-83dc446c-ae26-4ef2-91a0-01ffd6b97bcd button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jg3Gj8zTqEbf"
      },
      "source": [
        "## 1.1 Creación de `Profiler` Class (4.0 puntos)\n",
        "\n",
        "Cree la clase `Profiler`. Como mínimo, esta debe tener las siguientes funcionalidades:\n",
        "\n",
        "1. El método constructor, el cual debe recibir los datos a procesar en formato `Pandas DataFrame`. Además, este método debe generar una carpeta en su directorio de trabajo con el nombre `EDA_fecha`, donde `fecha` corresponda a la fecha de ejecución en formato `DD-MM-YYYY`.\n",
        "\n",
        "2. El método `summarize`, el cual debe caracterizar las variables del Dataset. Como mínimo, se espera que su método pueda:\n",
        "    - Implementar una funcionalidad para filtrar y aplicar este método a una o más variables de interés.\n",
        "    - Reportar el tipo de variable\n",
        "    - Reportar el número y/o porcentaje de valores únicos de la variable\n",
        "    - Reportar el número y/o porcentaje de valores nulos\n",
        "    - Si la variables es numérica:\n",
        "        - Reportar el número y/o porcentaje de valores cero, negativos y outliers\n",
        "        - Reportar estadística descriptiva como el valor mínimo, máximo, promedio y los percentiles 25, 50, 75 y 100\n",
        "   - Levantar una alerta en caso de encontrar alguna anomalía fuera de lo común (el criterio debe ser ajustable por el usuario)\n",
        "   - Guardar sus resultados en el directorio `EDA_fecha/summary.txt`. El archivo debe separar de forma clara y ordenada los resultados de cada punto.\n",
        "\n",
        "3. El método `plot_vars`, el cual debe graficar la distribución e interraciones de las variables del Dataset. Como mínimo, se espera que su método pueda:\n",
        "    - Crear la carpeta `EDA_fecha/plots`\n",
        "    - Implementar una funcionalidad para filtrar y aplicar este método a una o más variables de interés.\n",
        "    - Para las variables numéricas:\n",
        "        - Genere un gráfico de distribución de densidad\n",
        "        - Grafique la correlación entre las variables\n",
        "    - Para las variables categóricas:\n",
        "        - Genere un histograma de las top N categorías (N debe ser un parámetro ajustable)\n",
        "        - Grafique el coeficiente V de Cramer entre las variables\n",
        "    - Guardar cada gráfico generado en la carpeta `EDA_fecha/plots` en formato `.pdf` y bajo el naming `variable.pdf`, donde `variable` es el nombre de la variable de interés\n",
        "    \n",
        "4. El método `clean_data`, el cual debe limpiar los datos para que luego puedan ser procesados. Como mínimo, se espera que su método pueda:\n",
        "    - Crear la carpeta `EDA_fecha/clean_data`\n",
        "    - Implementar una funcionalidad para filtrar y aplicar este método a una o más variables de interés.\n",
        "    - Drop de valores duplicados\n",
        "    - Implementar como mínimo 2 técnicas para tratar los valores nulos, como:\n",
        "        - Drop de valores nulos\n",
        "        - Imputar valores nulos con alguna técnica de imputación\n",
        "        - Funcionalidad para escoger entre una técnica y la otra.\n",
        "    - Una de las columnas del dataframe presenta datos *no atómicos*. Separe dicha columna en las columnas que la compongan.\n",
        "        - Hint: ¿Qué caracteres permiten separar una columna de otra?\n",
        "        - Para las pruebas con el dataset nuevo, puede esperar que exista al menos una columna con este tipo de problema. Asuma que los separadores serán los mismos, aunque el número de columnas a separar puede ser distinto.\n",
        "    - Deberían usar `FunctionTransformer`.\n",
        "    - Guardar los datos procesados en formato `.csv` en el path `EDA_fecha/clean_data/data.csv`\n",
        "\n",
        "5. El método `scale`, el cual debe preparar adecuadamente los datos para luego ser consumidos por algún tipo de algoritmo. Como mínimo, se espera que su método pueda:\n",
        "    - Crear la carpeta `EDA_fecha/scale`\n",
        "    - Procesar de forma adecuada los datos numéricos y categóricos:\n",
        "        - Su método debe recibir las técnicas de escalamiento como argumento de entrada (utilizar solo técnicas compatibles con el framework de `sklearn`)\n",
        "        - Para los atributos numéricos, se transforme los datos con un escalador logarítmico y un `MinMaxScaler`\n",
        "        - Asuma que no existen datos ordinales en su dataset\n",
        "    - Guardar todo este procesamiento en un `ColumnTransformer`.\n",
        "    - Guardar los datos limpios y transformados en formato `.csv` en el path `EDA_fecha/process/scaled_features.csv`\n",
        "\n",
        "6. El método `make_clusters`, el cual debe generar clusters de los datos usando algún algoritmo de clusterización. Como mínimo, se espera que su método pueda:\n",
        "    - Crear la carpeta `EDA_fecha/clusters`\n",
        "    - Generar un estudio del codo donde señale la cantidad de clusters optimos para el desarrollo.\n",
        "    - Su método debe recibir el algoritmo de clustering como argumento de entrada (utilizar solo algoritmos compatibles con el framework de `sklearn`).\n",
        "    - No olvide pre procesar adecuadamente los datos antes de implementar la técnica de clustering.\n",
        "    - En este punto es espera que generen un `Pipeline` de sklearn. Además, su método debería usar lo construido en los puntos 4 y 5.\n",
        "    - Su método debe ser capaz de funcionar a partir de datos crudos (se descontará puntaje de lo contrario).\n",
        "    - Una vez generado los clusters, proyecte los datos a 2 dimensiones usando su técnica de reducción de dimensionalidad favorita y grafique los resultados coloreando por cluster.\n",
        "    - Guardar los datos con su respectivo cluster en formato `.csv` en el path `EDA_fecha/clusters/data_clusters.csv`. Guarde también los gráficos generados en el mismo path.\n",
        "\n",
        "7. El método `detect_anomalies`, el cual debe detectar anomalías en los datos. Como mínimo, se espera que su método pueda:\n",
        "\n",
        "    - Crear la carpeta `EDA_fecha/anomalies`\n",
        "    - Implementar alguna técnica de detección de anomalías.\n",
        "    - Al igual que el punto anterior, su método debe considerar los siguientes puntos:\n",
        "        - No olvide pre procesar de forma adecuada los datos antes de implementar la técnica de detección de anomalía.\n",
        "        - En este punto es espera que generen un `Pipeline` de sklearn. Además, su método debería usar lo construido en los puntos 4 y 5.\n",
        "        - Su método debe ser capaz de funcionar a partir de datos crudos (se descontará puntaje de lo contrario).\n",
        "        - Su método debe recibir el algoritmo como argumento de entrada\n",
        "        - Una vez generado las etiquetas, proyecte los datos a 2 dimensiones y grafique los resultados coloreando por las etiquetas predichas por el detector de anomalías\n",
        "    - Guardar los datos con su respectiva etiqueta en formato `.csv` en el path `EDA_fecha/anomalies/data_anomalies.csv`. Guarde también los gráficos generados en el mismo path.\n",
        "\n",
        "8. El método `profile`, el cual debe ejecutar todos los métodos anteriores.\n",
        "\n",
        "9. Crear el método `clearGarbage` para eliminar las carpetas/archivos creados/as por la clase `Profiler`.\n",
        "\n",
        "Algunas consideraciones generales:\n",
        "- Su clase será testeada con datos tabulares diferentes a los provistos. No desarrollen código *hardcodeado*: su clase debe ser capaz de funcionar para **cualquier** dataset.\n",
        "- Aplique todo su conocimiento sobre buenas prácticas de programación: se evaluará que su código sea limpio y ordenado.\n",
        "- Recuerden documentar cada una de las funcionalidades que implementen.\n",
        "- Recuerden adjuntar sus `requirements.txt` junto a su entrega de proyecto. **El código que no se pueda ejecutar por imcompatibilidades de librerías no será corregido.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "SXDJFZN-qEbg"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Profiler():\n",
        "\n",
        "    def __init__(self, data: pd.DataFrame):\n",
        "        \"\"\"\n",
        "        Inicializa la clase Profiler con el DataFrame proporcionado y crea una carpeta\n",
        "        para almacenar los resultados del EDA con la fecha actual como referencia.\n",
        "\n",
        "        Args:\n",
        "            data (pd.DataFrame): El DataFrame a analizar.\n",
        "        \"\"\"\n",
        "        self.data = data\n",
        "\n",
        "        # Crear carpeta con el formato EDA_fecha\n",
        "        self.folder_name = \"EDA_\" + datetime.datetime.now().strftime('%d-%m-%Y')\n",
        "        if not os.path.exists(self.folder_name):\n",
        "            os.makedirs(self.folder_name)\n",
        "\n",
        "###SUMMARIZE###\n",
        "    def summarize(self, cols=None, factor_outlier=1.5):\n",
        "        \"\"\"\n",
        "        Resumen de estadísticas descriptivas para las columnas del DataFrame.\n",
        "        Puede calcular y alertar sobre la presencia de valores atípicos usando el método del rango intercuartílico (IQR).\n",
        "\n",
        "        Args:\n",
        "            cols (list, optional): Columnas específicas a resumir. Si es None, resume todas las columnas.\n",
        "            factor_outlier (float): Factor para identificar valores atípicos basado en el IQR.\n",
        "        \"\"\"\n",
        "        if cols:\n",
        "            df = self.data[cols]\n",
        "        else:\n",
        "            df = self.data\n",
        "\n",
        "        summary = {}\n",
        "        for col in df.columns:\n",
        "            summary[col] = {}\n",
        "            summary[col]['tipo'] = df[col].dtype\n",
        "            summary[col]['valores_unicos'] = df[col].nunique()\n",
        "            summary[col]['valores_nulos'] = df[col].isna().sum()\n",
        "\n",
        "\n",
        "            if df[col].dtype in ['int64', 'float64']:\n",
        "                summary[col]['valores_cero'] = (df[col] == 0).sum()\n",
        "                summary[col]['valores_negativos'] = (df[col] < 0).sum()\n",
        "\n",
        "                # Outliers\n",
        "                Q1 = df[col].quantile(0.25)\n",
        "                Q3 = df[col].quantile(0.75)\n",
        "                IQR = Q3 - Q1\n",
        "                outliers = df[(df[col] < (Q1 - factor_outlier * IQR)) | (df[col] > (Q3 + factor_outlier * IQR))] #aqui influye el valor del factor\n",
        "                if not outliers.empty:\n",
        "                    print(f\"¡Alerta! Se encontraron {len(outliers)} outliers en la columna '{col}'\")\n",
        "                summary[col]['outliers'] = len(outliers)\n",
        "\n",
        "                # Estadísticas descriptivas\n",
        "                summary[col]['min'] = df[col].min()\n",
        "                summary[col]['25%'] = df[col].quantile(0.25)\n",
        "                summary[col]['50%'] = df[col].quantile(0.50)\n",
        "                summary[col]['75%'] = df[col].quantile(0.75)\n",
        "                summary[col]['max'] = df[col].max()\n",
        "        #Resumen\n",
        "        with open(f'{self.folder_name}/summary.txt', 'w') as f:\n",
        "            for k, v in summary.items():\n",
        "                f.write(f\"{k}:\\n\")\n",
        "                for key, val in v.items():\n",
        "                    f.write(f\"  {key}: {val}\\n\")\n",
        "                f.write(\"\\n\")\n",
        "###PLOT_VARS###\n",
        "\n",
        "    def _cramers_v(self, x, y):\n",
        "        \"\"\" Función para calcular el coeficiente V de Cramer entre dos variables categóricas \"\"\"\n",
        "        confusion_matrix = pd.crosstab(x,y)\n",
        "        chi2 = chi2_contingency(confusion_matrix)[0]\n",
        "        n = confusion_matrix.sum().sum()\n",
        "        phi2 = chi2/n\n",
        "        r,k = confusion_matrix.shape\n",
        "        phi2corr = max(0, phi2-((k-1)*(r-1))/(n-1))\n",
        "        rcorr = r-((r-1)**2)/(n-1)\n",
        "        kcorr = k-((k-1)**2)/(n-1)\n",
        "        return np.sqrt(phi2corr/min((kcorr-1),(rcorr-1)))\n",
        "\n",
        "    def plot_vars(self, cols=None, top_n=10):\n",
        "        \"\"\"\n",
        "        Método que genera y guarda visualizaciones para las distribuciones de las variables\n",
        "        y sus correlaciones, tanto para variables numéricas como categóricas.\n",
        "\n",
        "        Para las variables numéricas, crea gráficos de densidad de distribución y un mapa de calor\n",
        "        de correlación. Para las variables categóricas, genera histogramas de las principales\n",
        "        categorías y calcula el coeficiente V de Cramer entre pares de variables categóricas.\n",
        "\n",
        "        Args:\n",
        "            cols (list, optional): Lista de columnas para las que se generarán las visualizaciones.\n",
        "                Si se omite, se utilizarán todas las columnas del DataFrame.\n",
        "            top_n (int, optional): Número de principales categorías a visualizar en los histogramas\n",
        "                para variables categóricas. Por defecto es 10.\n",
        "\n",
        "        Notas:\n",
        "            - Los gráficos generados se guardarán en el subdirectorio 'plots' dentro de la carpeta\n",
        "              correspondiente al EDA con la fecha actual.\n",
        "            - Los archivos de gráficos se guardan en formato PDF.\n",
        "        \"\"\"\n",
        "        # Crear carpeta si no existe\n",
        "        plots_folder = f'{self.folder_name}/plots'\n",
        "        os.makedirs(plots_folder, exist_ok=True)\n",
        "\n",
        "        if cols:\n",
        "            df = self.data[cols]\n",
        "        else:\n",
        "            df = self.data\n",
        "\n",
        "        # Graficar distribución y correlación para variables numéricas\n",
        "        numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
        "        for col in numeric_cols:\n",
        "            plt.figure(figsize=(10,6))\n",
        "            sns.kdeplot(df[col], fill=True)\n",
        "            plt.title(f'Densidad de distribución de {col}')\n",
        "            plt.savefig(f'{plots_folder}/{col}.pdf')\n",
        "            plt.close()\n",
        "\n",
        "        if len(numeric_cols) > 1:\n",
        "            plt.figure(figsize=(10,6))\n",
        "            sns.heatmap(df[numeric_cols].corr(), annot=True, cmap='coolwarm', center=0)\n",
        "            plt.title('Correlación de las variables numéricas')\n",
        "            plt.savefig(f'{plots_folder}/correlation.pdf')\n",
        "            plt.close()\n",
        "\n",
        "      ###Categóricas###\n",
        "\n",
        "        #Top N\n",
        "        cat_cols = df.select_dtypes(include=['object']).columns\n",
        "        for col in cat_cols:\n",
        "            plt.figure(figsize=(10,6))\n",
        "            df[col].value_counts().head(top_n).plot(kind='bar')\n",
        "            plt.title(f'Top {top_n} categorías de {col}')\n",
        "            plt.savefig(f'{plots_folder}/{col}_histogram.pdf')\n",
        "            plt.close()\n",
        "\n",
        "        # Calcular y graficar el coeficiente V de Cramer\n",
        "        for i, col1 in enumerate(cat_cols):\n",
        "            for j, col2 in enumerate(cat_cols):\n",
        "                if i < j:  # para evitar repetir combinaciones\n",
        "                    value = self._cramers_v(df[col1], df[col2])\n",
        "                    plt.figure(figsize=(8, 5))\n",
        "                    sns.barplot(x=[col2], y=[value])\n",
        "                    plt.title(f\"Cramer's V between {col1} and {col2}\")\n",
        "                    plt.ylabel(\"Cramer's V\")\n",
        "                    plt.savefig(f'{plots_folder}/{col1}_VS_{col2}_cramersV.pdf')\n",
        "                    plt.close()\n",
        "\n",
        "###CLEAN DATA###\n",
        "\n",
        "    def _split_non_atomic(self, data, separators=[':', \"(\", \"?\", '*']):\n",
        "            \"\"\"\n",
        "            Función para dividir las columnas que contienen múltiples valores en una sola celda.\n",
        "\n",
        "            Args:\n",
        "                data (pd.DataFrame): El DataFrame con posibles columnas no atómicas.\n",
        "                separators (list): Lista de separadores utilizados para dividir las columnas.\n",
        "\n",
        "            Returns:\n",
        "                pd.DataFrame: DataFrame con las columnas divididas y valores convertidos a numéricos donde sea posible.\n",
        "            \"\"\"\n",
        "\n",
        "            # Escapar los separadores para regex\n",
        "            separators_regex = '|'.join(map(re.escape, separators))\n",
        "\n",
        "            # Identificar columnas no numéricas con separadores\n",
        "            non_atomic_columns = [\n",
        "                column for column in data.columns if not pd.api.types.is_numeric_dtype(data[column]) and\n",
        "                data[column].str.contains(separators_regex).any() and not data[column].str.contains(\"\\)\").any()\n",
        "            ]\n",
        "\n",
        "            # Procesar cada columna no atómica\n",
        "            for column in non_atomic_columns:\n",
        "                # Dividir la columna en múltiples columnas usando los separadores\n",
        "                split_data = data[column].str.split(separators_regex, expand=True)\n",
        "\n",
        "                # Asignar nuevos nombres a las columnas divididas\n",
        "                split_columns = [f'{column}_{i}' for i in range(split_data.shape[1])]\n",
        "                split_data.columns = split_columns\n",
        "\n",
        "                # Convertir a numérico si es posible\n",
        "                for split_column in split_columns:\n",
        "                    split_data[split_column] = pd.to_numeric(split_data[split_column], errors='coerce')\n",
        "\n",
        "                # Eliminar la columna original y unir las nuevas columnas al DataFrame\n",
        "                data = data.drop(column, axis=1).join(split_data)\n",
        "\n",
        "            # Reemplazar cadenas 'nan' con np.nan para uniformidad\n",
        "            data.replace('nan', np.nan, inplace=True)\n",
        "            return data\n",
        "\n",
        "\n",
        "    def _cleaning_operations(self, data, method, nan_threshold=0.5, cols_to_clean=None):\n",
        "        \"\"\"\n",
        "          Función para realizar operaciones de limpieza en el DataFrame, como eliminar columnas con\n",
        "          un alto porcentaje de valores NaN o imputar valores faltantes.\n",
        "\n",
        "          Args:\n",
        "              data (pd.DataFrame): DataFrame a limpiar.\n",
        "              method (str): Método de limpieza ('drop' o 'impute').\n",
        "              nan_threshold (float): Umbral para la proporción de NaNs permitidos antes de eliminar una columna.\n",
        "              cols_to_clean (list): Columnas específicas a limpiar. Si es None, limpia todo el DataFrame.\n",
        "\n",
        "          Returns:\n",
        "              pd.DataFrame: DataFrame limpio.\n",
        "        \"\"\"\n",
        "        #Si es que hay columnas en específico que limpiar\n",
        "        if cols_to_clean:\n",
        "            df_to_clean = data[cols_to_clean].drop_duplicates()\n",
        "        else:\n",
        "            df_to_clean = data.drop_duplicates()\n",
        "        #Eliminar columnas con muchos NAN\n",
        "        threshold = len(df_to_clean) * nan_threshold\n",
        "        df_to_clean = df_to_clean.dropna(thresh=threshold, axis=1)\n",
        "\n",
        "        #Métodos para los NAN, de defecto es drop\n",
        "        if method == \"drop\":\n",
        "            df_to_clean.dropna(inplace=True)\n",
        "        elif method == \"impute\":\n",
        "            for col in df_to_clean.columns:\n",
        "                if pd.api.types.is_numeric_dtype(df_to_clean[col]):\n",
        "                    df_to_clean[col].fillna(df_to_clean[col].median(), inplace=True)\n",
        "                else:\n",
        "                    df_to_clean[col].fillna(df_to_clean[col].mode()[0], inplace=True) #Para las categóricas\n",
        "\n",
        "        if cols_to_clean:\n",
        "            # Reemplazar las columnas originales con las limpiadas en el DataFrame completo\n",
        "            data.update(df_to_clean)\n",
        "            return data\n",
        "        else:\n",
        "            return df_to_clean\n",
        "\n",
        "    def clean_data(self, cols_to_clean=None, method=\"drop\", nan_threshold=0.5):\n",
        "\n",
        "        \"\"\"\n",
        "        Método  para limpiar el DataFrame. Divide primero las columnas no atómicas y luego realiza\n",
        "        las operaciones de limpieza especificadas.\n",
        "\n",
        "        Args:\n",
        "            cols_to_clean (list): Columnas específicas a limpiar. Si es None, limpia todo el DataFrame.\n",
        "            method (str): Método de limpieza a utilizar ('drop' o 'impute').\n",
        "            nan_threshold (float): Umbral para la proporción de NaNs permitidos antes de eliminar una columna.\n",
        "\n",
        "        Returns:\n",
        "            pd.DataFrame: DataFrame limpio.\n",
        "        \"\"\"\n",
        "        clean_data_folder = f'{self.folder_name}/clean_data'\n",
        "        os.makedirs(clean_data_folder, exist_ok=True)\n",
        "\n",
        "        # Aplicar _split_non_atomic a todo el DataFrame\n",
        "        split_transformer = FunctionTransformer(self._split_non_atomic)\n",
        "        df_split = split_transformer.transform(self.data.copy())\n",
        "\n",
        "        # Aplicar _cleaning_operations solo a las columnas especificadas\n",
        "        clean_transformer = FunctionTransformer(\n",
        "            self._cleaning_operations,\n",
        "            kw_args={'method': method, 'nan_threshold': nan_threshold, 'cols_to_clean': cols_to_clean}\n",
        "        )\n",
        "        df_clean = clean_transformer.transform(df_split)\n",
        "\n",
        "        df_clean.to_csv(f'{clean_data_folder}/data.csv', index=False)\n",
        "        return df_clean\n",
        "\n",
        "###SCALE###\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WQV2WC4qEbi"
      },
      "source": [
        "## 1.2 Caracterizar datos de Olimpiadas (2.0 puntos)\n",
        "\n",
        "A partir de la clase que hemos desarrollado previamente, procederemos a realizar un análisis exhaustivo de los datos proporcionados en el enunciado. Este análisis se presentará en forma de un informe contenido en el mismo Jupyter Notebook y abordará los siguientes puntos:\n",
        "\n",
        "1. Introducción\n",
        "    - Se proporcionará una breve descripción del problema que estamos abordando y se explicará la metodología que se seguirá.\n",
        "\n",
        "Elaborar una breve introducción con todo lo necesario para entender qué realizarán durante su proyecto. La idea es que describan de manera formal el proyecto con sus propias palabras y logren describir algunos aspectos básicos tanto del dataset como del análisis a realizar sobre los datos.\n",
        "\n",
        "Por lo anterior, en esta sección ustedes deberán ser capaces de:\n",
        "\n",
        "- Describir la tarea asociada al dataset.\n",
        "- Describir brevemente los datos de entrada que les provee el problema.\n",
        "- Plantear hipótesis de cómo podrían abordar el problema.\n",
        "\n",
        "2. Análisis del EDA (Análisis Exploratorio de Datos)\n",
        "    - Se discutirán las observaciones y conclusiones obtenidas acerca de los datos proporcionados. A lo largo de su respuesta, debe responder preguntas como:\n",
        "        - ¿Como se comportan las variables numéricas? ¿y las categóricas?\n",
        "        - ¿Existen valores nulos en el dataset? ¿En qué columnas? ¿Cuantos?\n",
        "        - ¿Cuáles son las categorías y frecuencias de las variables categóricas?\n",
        "        - ¿Existen datos duplicados en el conjunto?\n",
        "        - ¿Existen relaciones o patrones visuales entre las variables?\n",
        "        - ¿Existen anomalías notables o preocupantes en los datos?\n",
        "3. Creación de Clusters y Anomalías\n",
        "    - Se justificará la elección de los algoritmos a utilizar y sus hiperparámetros. En el caso de clustering, justifique además el número de clusters.\n",
        "    \n",
        "4. Análisis de Resultados\n",
        "    - Se examinarán los resultados obtenidos a partir de los clústers y anomalías generadas. ¿Se logra una separación efectiva de los datos? Entregue una interpretación de lo que representa cada clúster y anomalía.\n",
        "5. Conclusión\n",
        "    - Se resumirán las principales conclusiones del análisis y se destacarán las implicaciones prácticas de los resultados obtenidos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVKdLopoqEbj"
      },
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}